{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "import pprint\n",
    "import dpath.util\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data and Save Data to Mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Data_insert_MongoDB(News, collection_name):\n",
    "    with open(News,\"rb\") as fp:\n",
    "    a = pickle.load(fp)\n",
    "    t = a.to_dict('records')\n",
    "    client = MongoClient(\"mongodb://192.168.87.135:27017\")\n",
    "    db = client[\"news\"]\n",
    "    posts = db[collection_name]\n",
    "    result = posts.insert_many(t)\n",
    "    result.inserted_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_insert_MongoDB(\"news_all_with_event_with_tags_5days\",\"news_all_epspointseven_with_event_5days\")\n",
    "Data_insert_MongoDB(\"valid_news_all_with_event_with_tags_5days\",\"valid_news_all_epspointseven_with_event_5days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Major Event and Minor Event(Outlier) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Event_making(collection_name):\n",
    "    client = MongoClient(\"mongodb://192.168.87.135:27017\")\n",
    "    db = client[\"news\"]\n",
    "    collection = db[collection_name]\n",
    "    news_list_temp = collection.aggregate(    [      { \"$group\" : { \"_id\" : {\"tag\":\"$tag\", \"subtag\":\"$subtag\"}, \"dmin\":{\"$min\":\"$datetime\"},\"dmax\":{\"$max\":\"$datetime\"},\"org_indexes\":{ \"$addToSet\" : \"$org_index\" }}}  ,{\"$project\":{\"diff\":{\"$subtract\":[\"$dmax\",\"$dmin\"]},\"org_indexes\":\"$org_indexes\",\"dmin\":\"$dmin\",\"dmax\":\"$dmax\"} }] )\n",
    "    return news_list_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_list_temp = Event_making(\"news_all_epspointseven_with_event_5days\")\n",
    "news_list_temp_v = Event_making(\"valid_news_all_epspointseven_with_event_5days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': {'tag': 2, 'subtag': 0}, 'diff': 0, 'org_indexes': [297, 296, 295, 294, 293, 292, 291, 290, 289, 288, 287, 286, 285, 284, 283, 282, 281, 280, 279, 278, 253, 252, 251, 250, 249, 248, 247, 246, 245, 244, 243, 277, 242, 275, 235, 261, 234, 259, 233, 257, 232, 236, 263, 237, 265, 238, 267, 239, 269, 240, 271, 241, 273, 254, 255, 256, 258, 260, 262, 264, 266, 268, 270, 272, 274, 276], 'dmin': datetime.datetime(2017, 12, 14, 0, 0), 'dmax': datetime.datetime(2017, 12, 14, 0, 0)}, {'_id': {'tag': 0, 'subtag': -1}, 'diff': 0, 'org_indexes': [34], 'dmin': datetime.datetime(2017, 12, 17, 0, 0), 'dmax': datetime.datetime(2017, 12, 17, 0, 0)}, {'_id': {'tag': -1, 'subtag': -1}, 'diff': 3283200000, 'org_indexes': [302, 300, 231, 230, 229, 228, 227, 226, 224, 223, 222, 221, 220, 219, 218, 216, 215, 214, 213, 212, 211, 210, 96, 95, 299, 11, 94, 92, 91, 88, 87, 10, 86, 84, 83, 80, 79, 9, 78, 76, 75, 72, 70, 64, 199, 63, 195, 62, 191, 61, 60, 183, 59, 58, 56, 55, 54, 53, 155, 52, 151, 51, 147, 50, 143, 48, 135, 47, 131, 174, 158, 150, 142, 14, 119, 39, 13, 111, 35, 12, 103, 82, 67, 205, 3, 209, 23, 198, 127, 43, 156, 45, 182, 68, 207, 90, 71, 8, 0, 77, 36, 166, 57, 171, 7, 181, 93, 31, 38, 49, 139, 6, 149, 46, 66, 203, 74, 190, 65, 22, 201, 217, 24, 206, 69, 25, 73, 26, 27, 81, 28, 85, 29, 1, 89, 30, 32, 4, 33, 37, 40, 5, 41, 42, 44, 97, 98, 99, 100, 301, 101, 102, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 132, 133, 134, 136, 15, 137, 138, 140, 141, 144, 145, 146, 148, 152, 16, 153, 154, 160, 17, 161, 162, 165, 168, 18, 169, 170, 172, 173, 176, 19, 177, 2, 178, 184, 20, 185, 186, 188, 189, 192, 21, 193, 194, 196, 197, 200, 202, 208], 'dmin': datetime.datetime(2017, 12, 8, 0, 0), 'dmax': datetime.datetime(2018, 1, 15, 0, 0)}, {'_id': {'tag': 1, 'subtag': 0}, 'diff': 259200000, 'org_indexes': [164, 163, 298, 157], 'dmin': datetime.datetime(2018, 1, 5, 0, 0), 'dmax': datetime.datetime(2018, 1, 8, 0, 0)}, {'_id': {'tag': 0, 'subtag': 0}, 'diff': 432000000, 'org_indexes': [204, 187, 180, 225, 159, 179, 167, 175], 'dmin': datetime.datetime(2018, 1, 6, 0, 0), 'dmax': datetime.datetime(2018, 1, 11, 0, 0)}]\n"
     ]
    }
   ],
   "source": [
    "news_list = list(news_list_temp)\n",
    "print(news_list)\n",
    "news_df = pd.DataFrame(news_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_df(news_list_temp):\n",
    "    news_list = list(news_list_temp)\n",
    "    news_df = pd.DataFrame(news_list)\n",
    "    return news_df\n",
    "news_df = list_to_df(news_list_temp)\n",
    "news_df_v = list_to_df(news_list_temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_tag(news_df):\n",
    "    tagsubtag = list(news_df[\"_id\"])\n",
    "    tagsubtag = pd.DataFrame(tagsubtag)\n",
    "    # preprocess the dataframe\n",
    "    news_df[\"diff\"] = (news_df[\"diff\"]/(60*60*24*1000))\n",
    "    news_df[\"tag\"] = tagsubtag[\"tag\"]\n",
    "    news_df[\"subtag\"] = tagsubtag[\"subtag\"]\n",
    "    news_df = news_df[(news_df.tag != -1) & (news_df.subtag != -1)]\n",
    "    news_df = news_df.sort_values([\"diff\"],ascending = [0])\n",
    "    return news_df\n",
    "news_df = transfer_tag(news_df)\n",
    "news_df_v = transfer_tag(news_df_v)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outlier_making(collection_name):\n",
    "    client = MongoClient(\"mongodb://192.168.87.135:27017\")\n",
    "    db = client[\"news\"]\n",
    "    collection = db[collection_name]\n",
    "    news_list_temp = collection.find({})\n",
    "    news_list = list(news_list_temp)\n",
    "    news_df_outlier = pd.DataFrame(news_list)\n",
    "    news_df_outlier=news_df_outlier.rename(columns = {'org_index':'org_indexes'})\n",
    "    # ---------------------------------------------\n",
    "    org_indexes_tmp = []\n",
    "    for index, row in news_df_outlier.iterrows():\n",
    "        tmp = []\n",
    "        tmp.append(row.loc[\"org_indexes\"])\n",
    "        org_indexes_tmp.append(tmp)\n",
    "    org_indexes_tmp\n",
    "    \n",
    "    news_df_outlier[\"org_indexes\"] = pd.Series(org_indexes_tmp)\n",
    "    # --------------------------------------------\n",
    "    news_df_outlier = news_df_outlier[(news_df_outlier.tag == -1) | (news_df_outlier.subtag == -1)]\n",
    "    news_df_outlier.drop(\"_id\",1,inplace=True)\n",
    "    news_df_outlier[\"dmax\"] = news_df_outlier[\"datetime\"]\n",
    "    news_df_outlier[\"dmin\"] = news_df_outlier[\"datetime\"]\n",
    "    news_df_outlier[\"diff\"] = 0\n",
    "\n",
    "news_df_outlier = outlier_making(\"news_all_epspointseven_with_event_5days\")\n",
    "news_df_outlier_v = outlier_making(\"valid_news_all_epspointseven_with_event_5days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_event_outlier(news_df,news_df_outlier):\n",
    "    frames = [news_df,news_df_outlier]\n",
    "    result = pd.concat(frames)\n",
    "    return result\n",
    "\n",
    "result = merge_event_outlier(news_df,news_df_outlier)\n",
    "result_v = merge_event_outlier(news_df_v,news_df_outlier_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"Events_eps0.7_5days\",\"wb\") as fp:\n",
    "    pickle.dump(result,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"Valid_events_eps0.7_5days\",\"wb\") as fp:\n",
    "    pickle.dump(result_v,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values([\"dmin\"],ascending=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the days distribution of Events\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid') #預設作圖樣式\n",
    "import numpy as np\n",
    "fig = plt.figure(figsize = (400,6)) \n",
    "ax = plt.axes()\n",
    "pltx = np.array(result[\"dmin\"])\n",
    "plty = np.array(result[\"diff\"])\n",
    "ax.plot(pltx, plty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
